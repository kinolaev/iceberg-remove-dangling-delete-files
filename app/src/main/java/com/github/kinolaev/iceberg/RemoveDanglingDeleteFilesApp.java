/*
 * This source file was generated by the Gradle 'init' task
 */
package com.github.kinolaev.iceberg;

import io.opentelemetry.api.GlobalOpenTelemetry;
import io.opentelemetry.api.OpenTelemetry;
import org.apache.iceberg.actions.RemoveDanglingDeleteFiles;
import org.apache.iceberg.actions.RemoveDanglingDeleteFilesAction;
import org.apache.iceberg.catalog.Namespace;
import org.apache.iceberg.catalog.TableIdentifier;
import org.apache.iceberg.rest.RESTCatalog;
import org.apache.iceberg.Table;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.FileInputStream;
import java.io.IOException;
import java.util.Arrays;
import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

public class RemoveDanglingDeleteFilesApp {
    private static final OpenTelemetry openTelemetry = GlobalOpenTelemetry.get();
    static { io.opentelemetry.instrumentation.logback.appender.v1_0.OpenTelemetryAppender.install(openTelemetry); }
    private static final Logger logger = LoggerFactory.getLogger(RemoveDanglingDeleteFilesApp.class);

    public static void main(String[] args) throws ExecutionException, InterruptedException, IOException {
        String catalogName = args[0];
        Properties catalogProperties = new Properties();
        catalogProperties.load(new FileInputStream(args[1]));
        catalogProperties.load(new FileInputStream(args[2]));
        String sparkSqlCatalogPrefix = "spark.sql.catalog.%s.".formatted(catalogName);
        int sparkSqlCatalogPrefixLength = sparkSqlCatalogPrefix.length();
        Map<String, String> catalogProps = catalogProperties.stringPropertyNames().stream()
                .collect(Collectors.toMap(
                    key -> key.startsWith(sparkSqlCatalogPrefix)
                        ? key.substring(sparkSqlCatalogPrefixLength)
                        : key,
                    catalogProperties::getProperty));
        List<Namespace> namespaces = Arrays.stream(args[3].split(",")).map(Namespace::of).toList();
        int period = args.length < 5 ? -1 : Integer.parseInt(args[4]);

        try (RESTCatalog catalog = new RESTCatalog();
            ScheduledExecutorService executor = Executors.newScheduledThreadPool(1)) {
            catalog.initialize(catalogName, catalogProps);
            if (period < 0) {
                run(catalog, namespaces);
            } else {
                executor.scheduleAtFixedRate(() -> run(catalog, namespaces), 0, period, TimeUnit.SECONDS).get();
            }
        }
    }

    public static void run(RESTCatalog catalog, List<Namespace> namespaces) {
        for (Namespace namespace : namespaces) {
            for (TableIdentifier tableId : catalog.listTables(namespace)) {
                Table table = catalog.loadTable(tableId);
                try {
                    RemoveDanglingDeleteFiles.Result result =
                            new RemoveDanglingDeleteFilesAction(table).execute();
                    Collection<?> removedDeleteFiles = (Collection<?>) result.removedDeleteFiles();
                    logger.info("RemoveDanglingDeleteFiles.Result {} {}", tableId, removedDeleteFiles.size());
                } catch (Exception e) {
                    logger.error("RemoveDanglingDeleteFiles.Error", e);
                }
            }
        }
    }
}
